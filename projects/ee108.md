---
layout: default
title: FPGA Audio Synthesizer & Visualizer
---

<div class="project-header" style="margin-bottom: 30px;">
  <h1>FPGA Audio Synthesizer & Real-Time Visualizer</h1>
  <p class="subtitle" style="color: #666; font-size: 1.2rem;">A complete hardware audio stack: Wavetable Synthesis, DSP Effects, and VGA Visualization.</p>
  
  <div style="margin-top: 15px;">
    <a href="https://github.com/zackattack160/ee108-lab5" class="btn" style="background: #24292e; color: white; padding: 8px 15px; text-decoration: none; border-radius: 5px; margin-right: 10px;">View Code on GitHub</a>
    <a href="/assets/documents/ee108-report.pdf" class="btn" style="background: #0366d6; color: white; padding: 8px 15px; text-decoration: none; border-radius: 5px;">Download System Report (PDF)</a>
  </div>
</div>

## 1. System Architecture
This project integrates a digital audio synthesizer with a real-time video oscilloscope. The architecture is split into two clock domains: the Audio Domain (running at 48 kHz) and the Video Domain (running at 100 MHz).

![System Overview Block Diagram](/assets/images/ee108/block-diagram.png)
*Figure 1: High-level architecture. The Music Player (Lab 4) generates samples which are fed into the Wave Capture module (Lab 5). A dual-port RAM buffers the data to cross the clock domain to the VGA driver.*

---

## 2. The Synthesis Engine (Audio Generation)
The core of the audio generation is a "Note Player" module that implements **Direct Digital Synthesis (DDS)**. Instead of simply playing back recorded files, the system generates sine waves in real-time by stepping through a lookup table (ROM).

![Note Player Architecture](/assets/images/ee108/note-player.png)
*Figure 2: The Note Player datapath. It uses a Frequency ROM to determine the phase increment (step size) for the Sine Reader.*

* **Sine Reader:** Uses a 20-bit accumulator to step through a 1024-entry Sine ROM. To save memory, we only stored one quadrant of the sine wave and used logic to flip/mirror the output for the other three quadrants.
* **Frequency Precision:** We used fixed-point arithmetic (10.10 format) for the step size to ensure precise pitch accuracy, preventing the audio from sounding detuned over time.

---

## 3. The Visualization Engine (VGA Oscilloscope)
The major engineering challenge was bridging the **Audio Domain (48 kHz)** and the **Video Domain (100 MHz)**. To prevent visual tearing and metastability, I implemented a "Ping-Pong" buffer scheme.

### Control Logic (FSM)
The visualization is controlled by a finite state machine that triggers data capture only when the audio signal crosses from negative to positive (Zero-Crossing Detection). This ensures the waveform remains stable on the screen.

![Capture FSM](/assets/images/ee108/wave-capture-fsm.png)
*Figure 3: The Wave Capture FSM. It transitions from 'Armed' to 'Active' only upon detecting a zero-crossing event.*

* **Armed State:** Waits for the signal to cross zero.
* **Active State:** Captures 256 samples into the Write Buffer.
* **Wait State:** Holds until the VGA display finishes its current frame before swapping buffers.

---

## 4. Verification & Simulation
Before synthesis, the design was verified using ModelSim. Below is the waveform simulation for the `wave_capture` module, confirming that the `write_enable` signal asserts exactly when the audio sample transitions.

![Simulation Waveforms](/assets/images/ee108/waveforms.png)
*Figure 4: ModelSim results showing the FSM triggering capture (write_enable high) immediately after a zero-crossing event.*

---

## 5. Final Project Extensions: Polyphony & DSP
For the final iteration, we extended the architecture to support advanced audio features.

### Polyphonic Synthesis
The base system could only play one note at a time. We upgraded the `Note Player` to support **chords (up to 23 simultaneous notes)**.
* **Implementation:** The system iterates through active notes within a single 48kHz audio frame, accumulating their sample values.
* **Saturation Logic:** To prevent integer overflow (which causes harsh digital clipping), we implemented a custom saturation adder that clamps the signal at the 16-bit maximum (`16'h7FFF`).

### Hardware Echo Effect
We built a real-time delay line using a circular buffer in BRAM.

<div style="display: flex; flex-wrap: wrap; gap: 10px; align-items: center; justify-content: center;">
  <img src="/assets/images/ee108/echoblock1.png" alt="Echo Addressing" style="width: 48%; min-width: 300px;">
  <img src="/assets/images/ee108/echoblock2.png" alt="Echo Processing" style="width: 48%; min-width: 300px;">
</div>
*Figure 5: The Echo effect architecture (Memory Addressing & Signal Processing). It mixes the dry signal with a delayed, attenuated "wet" signal.*

* **Circular Buffering:** The read pointer trails the write pointer by a user-defined `delay_samples` offset.
* **Bitwise Attenuation:** Instead of expensive hardware multipliers, we used arithmetic right shifts (`>>>`) to decay the echo volume (e.g., shifting by 1 reduces volume by 50%).

---

## 6. Implementation Results
The final design was synthesized and routed successfully on the Zynq-7000 FPGA.

| Metric | Result | Notes |
| :--- | :--- | :--- |
| **Worst Negative Slack** | +1.289ns | Met 100MHz timing constraints |
| **Critical Path** | 7 Logic Levels | Located in the VGA pixel validation logic |
| **BRAM Usage** | < 5% | Efficient use of memory for lookups & buffers |

<br>
<p style="text-align: center; font-style: italic;">
  <a href="https://github.com/zackattack160/ee108-lab5">View the full Verilog source code on GitHub.</a>
</p>
